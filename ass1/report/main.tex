\documentclass[]{article}
\usepackage{float}
\usepackage{graphicx}

\newcommand{\TwoRowCell}[2][c]{%
\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}

\title{Simulation - Assignment 1}
\author{Anton Roth}
\date{\today}

\begin{document}
\begin{titlepage}
  \maketitle
  \thispagestyle{empty}
\end{titlepage}

\section{Task 1}
The system with two queues was implemented with the {\it Event-Scheduling} approach. The states for the system were; Length of Q2, number of arrivals to Q1 and number of rejected arrivals to Q1. Four events were implemented: Arrival to Q1, Departure of Q1 (combined with arrival to Q2), Departure of Q2 and Measure.

As model verifications the following was controlled numerically and graphically:
\begin{itemize}
  \item Inter-arrival times $\rightarrow 0$ :
    \begin{itemize}
      \item Length of Q1 $\rightarrow 10$.
      \item Rejection ratio of Q1 $\rightarrow 1$.
    \end{itemize}
  \item Inter-arrival times $\rightarrow \infty$ :
    \begin{itemize}
      \item Length of Q1 $\rightarrow 0$.
      \item Rejection ratio of Q1 $\rightarrow 0$.
    \end{itemize}
\end{itemize}

Measurements were made with time-differences exponentially distributed with a mean of 5 s. 10000 measurements were taken. The results of task 1 is presented in Table \ref{tab:task1}.

\begin{table}[H]
  \centering
  \caption{Results of task 1. For the three different inter-arrival times the mean value and the corresponding standard deviation (StdDev) is presented for length of Q2 and the rejection ratio of Q1.}
  \label{tab:task1}
  \resizebox{\textwidth}{!}{% Important that this only covers the tabular!
  \begin{tabular}{|c|c|c|c|c|}
  \hline
  \TwoRowCell{\bf Inter-arrival \\ \bf times Q1 (s)} & \TwoRowCell{\bf Mean length \\ \bf Q2} & \TwoRowCell{\bf StdDev length \\ \bf Q2} & \TwoRowCell{\bf Mean rejection \\ \bf ratio Q1} & \TwoRowCell{\bf StdDev rejection \\ \bf ratio Q1} \\ \hline
  1                                   & 11                      & 13                        & 0.52                             & 0.02                              \\ \hline
  2                                   & 4.4                     & 3.0                       & 0.070                            & 0.009                             \\ \hline
  5                                   & 0.43                    & 0.55                      & 0                                & 0                                 \\ \hline
  \end{tabular}%
}
\end{table}

From the results of length Q2 presented in Table \ref{tab:task1} it is impossible to draw proper conclusions as the uncertainties is of the same order as the mean. The rejection ratios are more significant and shows an expected behaviour, i.e. the shorter inter-arrival time the higher rejection rate.

Is it ok to assume that mean is normal distributed? This is {\it Central Limit Theorem}, right?

\section{Task 2}
The {\it Event-Scheduling} approach was also used in this task and the code written for task 1 was used as a template.
The event structure was changed and a specific method was implemented for the addition of a job to the buffer.
The following events were used: AddJobA, AddJobB, ServeJobA, ServeJobB and Measure.
The states were simply the number of job type A, denoted $NA$ and B, denoted $NB$, in the buffer.
Due to bad planning, an ugly solution was implemented for the case of adding a job from the buffer to serve (see code).

As a verification step the following was controlled:
\begin{itemize}
  \item Delay times $\rightarrow \infty$ :
    \begin{itemize}
      \item $NA + NB \rightarrow 0$. This is due to that the serve time of A, $x_A = 0.002$ s is shorter than the average arrival time $ \sim 0.0067$.
    \end{itemize}
  \item Serve time for job A and B $x_A, x_B \rightarrow \infty$ :
    \begin{itemize}
      \item $ NA + NB \rightarrow \infty$.
    \end{itemize}
\end{itemize}


\begin{table}[H]
  \centering
  \caption{Results of task 2 for the first three questions/simulation runs presented in the task description. For all runs the mean and standard deviation (StdDev) of the buffer length is presented.}
  \label{tab:task2}
  \resizebox{\textwidth}{!}{% Important that this only covers the tabular!
  \begin{tabular}{|c|c|c|}
  \hline
  \textbf{``Run''} & \TwoRowCell{\bf Mean length \\ \bf of buffer} & \TwoRowCell{\bf StdDev length \\ \bf of buffer} \\ \hline
  1                                   & 130                      & 100            \\ \hline
  2                                   & 7.2                    & 7.9          \\ \hline
  3                                   & 3.6                     & 3.8           \\ \hline
  \end{tabular}%
}
\end{table}

The result of run 1 and 2 differs substantially.
As job B is prioritised and feeded to a system with a delay of 1 s one obtains a periodicity.
Consider a constant delay of 1 s and the situation when the system starts up, the periodic behaviour can be explained with the following chain of events:
\begin{enumerate}
  \item Job A:s are added to the buffer and served efficiently. The buffer length is kept minimal.
  \item After 1 s job B:s are added to the buffer and since they are prioritised they are served immediately. The serving time is $ x_B > x_A $ and together with the fact that A jobs are continuously added to the buffer this implies that the buffer length will increase.
  \item After some time all B jobs have been served and A jobs are again served. The buffer length decreases.
  \item $\rightarrow$ point 2.
\end{enumerate}
Run 2 exhibits a weaker periodic behaviour since delay is now sampled from an exponential distribution.
This has the effect that all B jobs will not arrive at the server at the same time and the buffer length will not increase as much.

The mean length of the buffer for the third run is the lowest.
The buffer length no longer shows a clear periodic behaviour.
As A jobs now are prioritised and have a shorter serving time the buffer length can be efficiently be kept minimal.
When there are no A jobs, B jobs which have a longer serving time will be processed.
The pile-up in the buffer is not possible due to the efficient processing of the jobs.
Better description?

It should also be mentioned that there is a ``start-up'' period needed for the first run (although not implemented), as it takes some time for the buffer to stabilise in its periodic behaviour.
\section{Task 3}
A similar system compared to in task 1 was implemented.
One difference was the measure of the mean time a customer spends in the system.
The time spent by every customer in the system was stored in a container and used to calculate the mean.
Hence, it was not ``Measured'' as an event as this was considered the most efficient implementation and is not very computationally costly for the simulation.

Measurements were made with time-differences exponentially distributed with a mean of 5 s.
10000 measurements were taken.
The results of task 3 is presented in Table \ref{tab:task3}.

\begin{table}[H]
  \centering
  \caption{Results of task 3. For the three different mean arrival times the mean customer length and the mean queueing time for the simulation and analytical calculations are presented.}
  \label{tab:task3}
  \resizebox{\textwidth}{!}{% Important that this only covers the tabular!
  \begin{tabular}{|c|c|c|c|c|}
  \hline
  \TwoRowCell{\bf Mean arrival \\ \bf times (s)} & \TwoRowCell{\bf Mean customer \\ \bf length (simulated) } & \TwoRowCell{\bf Mean customer \\ \bf length (analytically) }& \TwoRowCell{\bf Mean queueing \\ \bf time (simulated) } & \TwoRowCell{\bf Mean queueing \\ \bf time (analytically) } \\ \hline
  2                                   & 1.98                      & 2                        & 3.99                             & 4                              \\ \hline
  1.5                                   & 4.02                     & 4                       & 5.99                            & 6                             \\ \hline
  1.1                                   & 18.5                    & 20                      & 20.2                                & 22                                 \\ \hline
  \end{tabular}%
}
\end{table}

The simulated values are very congruent with the analytical calculations in case of 2 and 1.5 s mean arrival times.
For the 1.1 s mean arrival time the simulated values deviate more from the analytical value.
The reason to why, is unclear.
A delayed start-up of 1000 s, chosen on the basis of the graphic evolution of the mean customer length, was tried but resulted in similar values.

\section{Task 4}
Task 4 was also solved with the {\it Event-Scheduling} approach and a similar implementation as in task 1.
Three events were defined; Arrival, Depart and Measure.
One system state was implemented as the number of customers, denoted $NC$,  in the system.

As model verifications the following was controlled numerically and graphically:
\begin{itemize}
  \item $ x \rightarrow 0$ : $ NC \rightarrow 0$
  \item $\lambda \rightarrow \infty$ : $ NC \rightarrow N$
\end{itemize}

\subsection{Question 1, 2 \& 3}
The simulation measurements for the settings in questions 1, 2 and 3 is presented in Figure \ref{fig:task4}.

Clear from Figure \ref{fig:task4} are different transient phases, i.e. time it takes till the system reaches an equilibrium in the total number of customers.
Reading out when the measurements plane out the length of the transient phases are obtained and this is presented in Table \ref{tab:task4a}.

\begin{table}[H]
  \centering
  \caption{Length of the transient phases for task 4 and the first three questions/simulation runs.}
  \label{tab:task4a}
  \begin{tabular}{|c|c|}
  \hline
  \textbf{``Run''} & \TwoRowCell{\bf Length of \\ \bf transient phase (s)} \\ \hline
  1 ($x = 100, \lambda = 8$)                                  & 100     \\ \hline
  2 ($x = 10, \lambda = 80$)                                 & 10 \\ \hline
  3 ($x = 200, \lambda = 4$)                                 & 200   \\ \hline
  \end{tabular}
\end{table}

For these three runs the number of customers in equilibrium is the same according to Little's theorem $ NC = \lambda \cdot x = 800$.
The parameter that governs the length of transient phase is the rate of arrivals to the system, $\lambda$.
The time it takes for the system to reach this number (assuming $ x >> \frac{1}{\lambda}$) is: $ t = \frac{800}{\lambda} $.

\subsection{Question 4, 5 \& 6}
The confidence interval is calculated using the provided {\it MATLAB} program.
In this program the system measurements are modeled as an auto-regressive process.
Why is this preferable model?
I would really appreciate an answer :)

The length of the 95\% confidence interval for the three different runs are presented in Table \ref{tab:task4b}.
\begin{table}[H]
  \centering
  \caption{Length of the 95\% confidence interval for task 4 and the last three questions/simulation runs.}
  \label{tab:task4b}
  \begin{tabular}{|c|c|}
  \hline
  \textbf{``Run''} & \TwoRowCell{\bf Length of \\ \bf 95\% confidence interval.} \\ \hline
  4 ($T = 4, M = 1000$)                                  & 1.17     \\ \hline
  5 ($T = 1, M = 4000$)                                 & 1.27 \\ \hline
  6 ($T = 4, M = 4000$)                                 & 0.64 \\ \hline
  \end{tabular}
\end{table}

Period of arrivals: $\frac{1}{\lambda} = 0.25$.

Why is run 5 just as bad and even worse than run 4?

More measurements will indeed lower the variance of the mean estimate and this is clear with run 6 where the length of the confidence interval is the shortest.

\section{Task 5}
The system in this task was implemented with the {\it Process Interaction} method.
It took quite some time to get it right.

Three different processes, i.e. classes, were implemented; Generator, Queue and Measure.
The interaction between the processes was implemented with a Signal class which comprised a SignalType, a receiving process Destination, and ArrivalTime, plus an optional parameter representing the measured values sent to the Measure process.
A helper class ProcessList holds all Processes and controlls the Signal which is to be treated.
A base class LoadDistr with derived classes RandomLoad, RobinLoad and OptLoad were also implemented.
The Generator process possesses an object of type LoadDistr which has a function GetQ which is invoked when choose Queue.

The system was first tried on just one Queue and verified with Little's theorem.
In this process it was noted that if the mean arrival time was smaller than the mean service time, the system diverged.

The system with all load distributions were then tried to be verified with a mean arrival time of 0.12 seconds.
However, the obtained mean number of jobs in the queuing system was not congruent with Little's theorem in this case.
It was assumed that








 \end{document}
