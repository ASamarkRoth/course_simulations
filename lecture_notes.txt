Lecture 1, 21/3
Labs voluntarily
Take home exam: over summer (!)
Home assignment deadlines: 5/5, 26/5 & 9/6

Simulations can be used to confirm developed analytical models
Different kind of systems:
	Continuous
	Discrete
	Hybrid
	Dynamic - time dependent
	Stochastic 
Verification vs. validation
	ver = test your model, does your program work as the model you developed with simple tests
	val = sanity checks?
Model concepts, slide 16
Random generate points of measurements: 
	Takes time to write to file
	How much data is desired?

Lecture 2, 23/3
Event scheduling method
	Smaller problems
	Also event-listing, this is how the events+times are stored
	Cf. queue and scheduling of departure and arrivals, but you need an initialisation trigger/kick-start.
	Events are times at which an action takes place, in this case arrival/departure.
		These events are stored in an ordered list wrt time.
Process-interaction method, slide 21
	Object orientation, process = object
	Use signal communication
	Matrix to keep track of event-list (2nd dimension = the process' signal list)
	Steps of constructing the process interaction : slide 39!
	Should read up upon the implementation of this method

Measurements:
	Be careful of biased measurements -> randomise times -> central limit theorem --> mean(process)

Lecture 3, 28/2
Verification
	Animation tools for discrete event simulations
	Comparison with analytical results (Little's theorem)
Pseudo-random numbers: deterministic sequence of numbers which "are random". Common: congruential generators.
Inverse CDF method for random numbers according to a probability distribution.
	Gaussian distr. Approximate inverse. If accuracy is important, examine the method to generated the distr. 

Error propagation:
	errors in input
	Standard error prop. holds: DeltaX << X

Lecture 4, 4/4
Mean is an unbiased estimator!
Use confidence intervals -> update during runtime and plot for better interpretation.
Warmup time: lag before the system reaches a steady state -> need to postpone measurements! Observe the properties of what you'd like to measure first. 
Confidence intervals implies data is uncorrelated. Always check if there is a correlation in the system.
Correlations can be calculated continuously during a run ...
Manipulating measurement frequency can improve correlation
Batch means - group your data and take means from these group as the measurements
FOR MORE STATISTICS:
Another good book that deals much more with the statistical side of discrete event simulation is:

    S. M. Ross, Simulation 4th ed., Academic Press 2006

    For more exensive analysis of time series from a statistical POV.

    Andreas Jakobsson, An Introduction to Time Series Modeling 2nd ed., Studentlitteratur 2015

Lecture 5, 6/4
Two options for simulations:
	Study behaviour
	Get optimal solution
Convex optimisation problem?
Combinatorial search -> discrete time space
Linear programming: Optimisation of linear problem (linear function)
Feasible region: region within which solutions exist
LP: solution is on a corner point!

Lecture 6, 2/5 (absent)
Heuristic - technique designed to solve problem but ignores whether the solution can be proven to be correct, but which usually produces a good solution. 
Advantages - run time
Combinatorial optimisation problem (COP) - optimising discrete structure, examples:
	Travelling salesman problem 
	Knapsack problem
Modification of a given solution gives a neighbour solution -> a set of such operations gives a neighbourhood.
2-opt: local search algorithm first proposed for TSP (take a route that crosses over itself)
A move: 
	go to neighbour solution with the neighbour operator NO!!
	Process of selecting a given solution in the neighbourhood of the current solution to be the "new" current solution. 
Local search: Iteratively search neighbourhood for best solution -> local optimum
	cf. Fission barrier random walk
How can we avoid the search stopping in a local optimum with local search? -> Metaheuristics
	Iterative controlling an underlying heuristic process to intelligently exploit search spaces 
Metaheuristics: 	
	Iterated Local Search (ILS)
	Simulated annealing (SA)
	Tabu Search (TS)
	Genetic Algorithms (GA)
	Scatter Search (SS)

Lecture 7, 4/5
ILS: Extension of local search - relies on controlled restart
	Change starting solution - with a perturbation of a certain strength
	Change random neighbour selection
	Change controlling parameter - Acceptance criterion (update solution)
	-> When a local optimum is reached, we perturb the solution in order to escape from the local optimum

SA - inspiration statistical thermodynamics (COOL!) (Metropolis alg)
	Control parameter = temperature
1. Choose random neighbour
2. Improving moves are always accepted
3. Deteriorating are accepted with a probability that depends on the amount of deterioration and on the temperature exp(-Delta/T)
Statistical guarantee that SA finds the global optimum.
Cooling schedule is important.
Stopping condition: lower limit of temperature

TS - Cut off search from parts of the search space (temporarily) and guide towards other parts with penalties and bonuses.
	Uses memory (don't visit same solution twice)
Aspiration criterion: Tabu neighbour might be selected anyway if it is deemed good enough
Attribute: A property of a solution or move (important to avoid visiting same solution and thus need to remember in some way)
Tabu tenure: Attribute is tabu for this amount of time
Diversification: Trying to get somewhere else, e.g. frequency based, i.e. penalise elements of the solution that have appeared in many other solutions visited.
Intensification: Aggressively prioritise attributes of good solutions in a new solution

* Book
– Modern heuristic techniques for combinatorial
problems/ by Colin R. Reeves
*  Papers:
– The theory and practice of simulated annealing/
by Darrall Henderson, Sheldon H. Jacobson,
and Alan W. Johnson
– An introduction to Tabu Search/ by Michel
Gendreau

Lecture 8, 9/5
VERY IMPORTANT TO TEST HEURISTICS WITH EXAMPLES
Genetic algorithms - Main difference, working with update of a population of solutions
Chromosome - solution representation
Biology analogies slide 10
Crossover and mutation operators -> evolution to new generations
Binary encoding is most established chromosome representation
Crossover slide 22
